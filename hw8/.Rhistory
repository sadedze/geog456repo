knitr::opts_chunk$set(echo = TRUE)
## Load tidyverse library
library(tidyverse)
## Download file
download.file("https://delamater.web.unc.edu/files/2019/09/SEDA_SD_SCORES.csv", "C:/GEOG215/GEOG215_Exam1_materials/SEDA_SD_SCORES.csv")
## Read in Data
dat <- read_csv("C:/GEOG215/GEOG215_Exam1_materials/SEDA_SD_SCORES.csv")
## Load spatial packages/libraries
library(sf)
library(tmap)
##
nc.sd.sp <- st_read("https://pauldelamater.net/geog215/exams/NCLEA.geojson")
## Convert layer from WGS 84 coordinate system to NC State Plane
nc.sd.sp <- st_transform(nc.sd.sp, crs = 2264)
View(nc.sd.sp)
## Join NC LEA academic score to spatial data
nc.sd.sp.join <- merge(nc.sd.sp, dat.nc, by.x = "GEOID", by.y = "LEA_ID", all.x = TRUE)
View(nc.sd.sp.join)
## Create map
tm_shape(nc.sd.sp.join) +
tm_polygons("AVESCORE",
style = "jenks",
palette = "Greens")
## Load spatial packages/libraries
library(sf)
library(tmap)
## Read in NC LEAs geojson file
nc.sd.sp <- st_read("https://pauldelamater.net/geog215/exams/NCLEA.geojson")
## Convert layer from WGS 84 coordinate system to NC State Plane
nc.sd.sp <- st_transform(nc.sd.sp, crs = 2264)
## Join NC LEA academic score to spatial data
nc.sd.sp.join <- merge(nc.sd.sp, dat.nc, by.x = "GEOID", by.y = "LEA_ID", all.x = FALSE)
## Create map
tm_shape(nc.sd.sp.join) +
tm_polygons("AVESCORE",
style = "jenks",
palette = "Greens")
## Load spatial packages/libraries
library(sf)
library(tmap)
## Read in NC LEAs geojson file
nc.sd.sp <- st_read("https://pauldelamater.net/geog215/exams/NCLEA.geojson")
## Convert layer from WGS 84 coordinate system to NC State Plane
nc.sd.sp <- st_transform(nc.sd.sp, crs = 2264)
## Join NC LEA academic score to spatial data
nc.sd.sp.join <- merge(nc.sd.sp, dat.nc, by.x = "GEOID", by.y = "LEA_ID", all.x = TRUE)
## Create map
tm_shape(nc.sd.sp.join) +
tm_polygons("AVESCORE",
style = "jenks",
palette = "Greens")
getwd()
getwd()
getwd()
knitr::opts_chunk$set(echo = TRUE)
#### Load libraries ####
library(tidyverse)
library(tmap)
library(sf)
#### Read in Data ####
nc_county_polys <- geojson_sf("https://opendata.arcgis.com/api/v3/datasets/d192da4d0ac249fa9584109b1d626286_0/downloads/data?format=geojson&spatialRefId=4326&where=1%3D1")
library(geojson)
library(geojsonsf)
#### Read in Data ####
nc_county_polys <- geojson_sf("https://opendata.arcgis.com/api/v3/datasets/d192da4d0ac249fa9584109b1d626286_0/downloads/data?format=geojson&spatialRefId=4326&where=1%3D1")
read_csv("https://www.pauldelamater.net/geog215/exams/NC_Vaccination_Data.csv")
View(nc_county_polys)
View(nc_county_polys)
#### Read in Data ####
nc_county_polys <- geojson_sf("https://opendata.arcgis.com/api/v3/datasets/d192da4d0ac249fa9584109b1d626286_0/downloads/data?format=geojson&spatialRefId=4326&where=1%3D1")
nc_vac_data <- read_csv("https://www.pauldelamater.net/geog215/exams/NC_Vaccination_Data.csv")
View(nc_vac_data)
View(nc_county_polys)
View(nc_vac_data)
nc_map <- merge(nc_county_polys,
nc_vac_data,
by= "NAME",
all.x = TRUE,
all.y = FALSE)
View(nc_vac_data)
View(nc_map)
View(nc_county_polys)
map <- tm_shape(nc_map) +
tm_polygons("POP_A12p",
style = "jenks",
palette = "Greens")
View(map)
tm_shape(nc_map) +
tm_polygons("POP_A12p",
style = "jenks",
palette = "Greens")
knitr::opts_chunk$set(echo = TRUE)
#### Load libraries ####
library(tidyverse)
library(tmap)
library(sf)
library(geojsonsf)
#### Read in Data ####
nc_county_polys <- geojson_sf("https://opendata.arcgis.com/api/v3/datasets/d192da4d0ac249fa9584109b1d626286_0/downloads/data?format=geojson&spatialRefId=4326&where=1%3D1")
nc_vac_data <- read_csv("https://www.pauldelamater.net/geog215/exams/NC_Vaccination_Data.csv")
nc_map <- merge(nc_county_polys,
nc_vac_data,
by= "NAME",
all.x = TRUE,
all.y = FALSE)
tm_shape(nc_map) +
tm_polygons("POP_A12p",
style = "jenks",
palette = "Greens")
View(nc_map)
View(nc_county_polys)
knitr::opts_chunk$set(echo = TRUE)
#### Load libraries ####
library(tidyverse)
library(tmap)
library(sf)
library(geojsonsf)
options(scipen=999)
library(ggplot2)
#### Read in Data ####
nc_county_polys <- geojson_sf("https://gis11.services.ncdot.gov/arcgis/rest/services/NCDOT_CountyBdy_Poly/MapServer/0/query?outFields=*&where=1%3D1&f=geojson")
nc_vac_data <- read_csv("https://www.pauldelamater.net/geog215/exams/NC_Vaccination_Data.csv")
nc_map <- merge(nc_county_polys,
nc_vac_data,
by= "NAME",
all.x = TRUE,
all.y = FALSE)
tm_shape(nc_map) +
tm_polygons("POP_A12p",
style = "jenks",
palette = "Greens")
View(nc_vac_data)
# Make Field With Percent of 12+ Vaccinated
nc_vac_data$perc_vac <- 100 * nc_vac_data$VACCINATED/nc_vac_data$POP_A12p
knitr::opts_chunk$set(echo = TRUE)
#### Load libraries ####
library(tidyverse)
library(tmap)
library(sf)
library(geojsonsf)
options(scipen=999)
library(ggplot2)
# Make Field With Percent of 12+ Vaccinated
nc_vac_data$perc_vac <- 100 * nc_vac_data$VACCINATED/nc_vac_data$POP_A12p
# Create Histogram
# geom_histogram()
install.packages("ggplot2")
install.packages("ggplot2")
# Create Histogram
ggplot(nc_vac_data, aes(perc_vac)) + geom_histogram()
# Create Histogram
ggplot(nc_vac_data, aes(perc_vac)) + geom_histogram(binwidth = 10)
# Create Histogram
ggplot(nc_vac_data, aes(perc_vac)) + geom_histogram(binwidth = .1)
# Create Histogram
ggplot(nc_vac_data, aes(perc_vac)) + geom_histogram(binwidth = 30)
# Create Histogram
ggplot(nc_vac_data, aes(perc_vac)) + geom_histogram(binwidth = 10)
# Create Histogram
ggplot(nc_vac_data, aes(perc_vac)) + geom_histogram(binwidth = 5)
# Create Histogram
ggplot(nc_vac_data, aes(perc_vac)) + geom_histogram(binwidth = 10)
# Create Histogram
ggplot(nc_vac_data, aes(perc_vac)) + geom_histogram()
# Download data file
download.file("https://www.pauldelamater.net/geog215/exams/GEOG215-Exam2-data.zip",
"GEOG215-Exam2-data.zip")
# Unzip data folder
unzip("GEOG215-Exam2-data.zip")
# Get a list of files in the unzipped folder so R can find out how many files there are
folder_contents <- list.files("GEOG215-Exam2-data/Data")
# Create empty object to prepare space where files can be read in later on in loop
n_files <- length(folder_contents)
getwd()
getwd()
getwd()
knitr::opts_chunk$set(echo = TRUE)
# Load in libraries
library(tidyverse)
library(dplyr)
library(geojsonsf)
library(stringr)
library(dbplyr)
library(tmap)
library(sf)
library(vctrs)
knitr::opts_chunk$set(echo = TRUE)
# Load in libraries
library(tidyverse)
library(dplyr)
library(geojsonsf)
library(stringr)
library(dbplyr)
library(tmap)
library(sf)
library(vctrs)
library(psych)
install.packages(psych)
install.packages("psych")
knitr::opts_chunk$set(echo = TRUE)
# Load in libraries
library(tidyverse)
library(dplyr)
library(geojsonsf)
library(stringr)
library(dbplyr)
library(tmap)
library(sf)
library(vctrs)
library(psych)
library(ggplot2)
# Download diabetes data
diab_data <- read_csv("../Data/DiabetesAtlasData.csv")
# Read in US counties shapefile
nc_county_polys <- geojson_sf("https://gis11.services.ncdot.gov/arcgis/rest/services/NCDOT_CountyBdy_Poly/MapServer/0/query?outFields=*&where=1%3D1&f=geojson")
# Subset for NC obs. only
nc_diab_data <- filter(diab_data, State== "North Carolina")
# Rename diabetes percentage column for brevity
colnames(nc_diab_data)[5] = "diab_percent"
# Harmonize county names
nc_diab_2 <- nc_diab_data %>%
mutate(County = str_remove_all(County, " County"))
# Rename common attribute column
colnames(nc_diab_2)[3] = "UpperCountyName"
# Make county names all uppercase
nc_diab_2$UpperCountyName <- toupper(nc_diab_2$UpperCountyName)
# Test if a perfect match
all(nc_diab_2$UpperCountyName %in% nc_county_polys$UpperCountyName)
describe(nc_diab_2[, c('diab_percent')], fast=TRUE)
View(nc_diab_2)
install.packages("vtable")
library(vtable)
st(nc_diab_2, vars = c('diab_percent'))
data(nc_diab_2)
sumtable(nc_diab_2,
summ=c('notNA(x)',
'mean(x)',
'median(x)',
'propNA(x)'))
data(nc_diab_2)
View(nc_diab_2)
st(nc_diab_2, var = c('diab_percent'))
data(nc_diab_2)
st(nc_diab_2, var = c('diab_percent'),
summ = c('notNA(x)','countNA(x)','min(x)', 'max(x)', 'mean(x)','sd(x)' ))
ggplot(nc_diab_2,
aes(x = diab_percent)) +
geom_histogram()
ggplot(nc_diab_2,
aes(x = diab_percent)) +
geom_histogram(binwidth = 2)
ggplot(nc_diab_2,
aes(x = diab_percent)) +
geom_histogram(binwidth = .05)
ggplot(nc_diab_2,
aes(x = diab_percent)) +
geom_histogram(binwidth = .5)
ggplot(nc_diab_2,
aes(x = diab_percent)) +
geom_histogram(binwidth = .25)
ggplot(nc_diab_2,
aes(x = diab_percent)) +
geom_histogram(binwidth = .5)
ggplot(nc_diab_2,
aes(x = diab_percent)) +
geom_histogram(binwidth = .5)
#### Table Join ####
nc_map <- merge(nc_county_polys,
nc_diab_2,
by= "UpperCountyName")
#### Create Map ####
tmap_mode("view")
tm_shape(nc_map) +
tm_polygons("diab_percent",
style = "jenks",
palette = "YlOrRd")
knitr::opts_chunk$set(echo = TRUE)
```{r setup, include=FALSE}
# Download diabetes data
diab_data <- read_csv("../Data/DiabetesAtlasData.csv")
devtools::install_github("benmarwick/wordcountaddin", type = "source", dependencies = TRUE)
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
devtools::install_github("benmarwick/wordcountaddin", type = "source", dependencies = TRUE)
install.packages("swirl")
install.packages("Rtools")
library("swirl")
swirl()
5 + 7
x <- 5 = 7
x <- 5 + 7
x
y <- x-3
y
z <- c(1.1, 9, 3.14)
?c
z
c(z, 555, z)
z * 2 + 100
mysqrt <- sqrt(z-1)
sqrt(z-1)
my_sqrt <- sqrt(z-1)
my_sqrt
my_div <- z/my_sqrt
my_div
c(1, 2, 3, 4) + c(0, 10)
c(1, 2, 3, 4) + c(0, 10, 100)
z * 2 + 100
z * 2 + 1000
my_div
swirl()
getwd()
ls()
x <-9
ls()
list.files()
?list.files
args(list.files)
old.dir<-119
old.dir <- getwd()
dir.create("testdir")
setwd(testdir)
setwd("testdir")
file.create("mytest.R")
list.files()
file.exists("mytest.R")
file.info("mytest.R")
file.rename("mytest.R")
file.rename("mytest.R") to "mytest2.R"
?file.rename
file.rename("mytest.R", "mytest2.R")
file.copy("mytest2.R", "mytest3.R")
file.path("mytest3.R")
args(file.path)
file.path("folder1", "folder2")
?dir.create
dir.create(file.path("testdir2", "testdir3"))
dir.create(file.path("testdir2", "testdir3"), recursive = TRUE)
setwd(old.dir)
swirl()
1:20
pi:10
15:1
?`:`
seq(1,20)
seq(0,10, by=0.5)
my_seq <- seq(5,10, length=30)
length(my_seq)
1:length(my_seq)
seq(along.with = my_seq)
seq_along(my_seq)
rep(0, times = 40)
rep(c(0,1,2), times=10)
rep(c(0,1,2), each=10)
nyc2014 <- c(2014,1206,71,508,25)
nyc2014
nyc2023<-c(2023,460,58,238,67)
nyc2023
NYCartoons<-data.frame(rbind(nyc2014,nyc2023))
NYCartoons
?colnames
colnames(NYCartoons)<-c("year", "wm", "nwm", "wf", "nwf")
NYCartoons
cor_trees<-cor(trees)
cor_trees
attach(trees)
cor(trees)
plot(Volume,Girth)
plot(Girth,Volume)
# add best fit line
abline(lsfit(Girth,Volume))
Girth
x<-c(1,2,3,4,5,6,7,8,9,10)
y<-c(21, 15, 30, 20, 36, 10, 40, 55, 72, 61)
plot(x,y)
abline(lsfit(x,y))
x<-c(1,2,3,4,5,6,7,8,9,10)
y<-c(21, 15, 30, 20,10, 40, 55, 72, 61)
plot(x,y)
gety <- function(x) {
y<- x^2
y
}
gety(17)
conevol<- function(h,d) {
vol<- (h/3)*pi*((d/2)^2)
vol
}
?trees
conevol<- function(h,r) {
vol<- (h/3)*pi*(r^2)
vol
}
h = trees[17,2]*12
r = trees[17,1]/2
conevol(h,r)
conevol<- function(h,r) {
vol<- (h/3)*pi*(r^2)
vol
}
# transform var to have same units
h = trees[17,2]
r = (trees[17,1]/2)12
conevol<- function(h,r) {
vol<- (h/3)*pi*(r^2)
vol
}
# transform var to have same units
h = trees[17,2]
r = (trees[17,1]/2)/12
# Find cone volume
conevol(h,r)
type=c(rep("B",8),rep("M",8))
animal = c("canary","pigeon","crow","buzzard","wild duck","hen","domestic duck","turkey","mouse","rat","guinea pig","rabbit","small dog","large dog","man","horse")
mass = c(20,300,341,658,1100,2000,2300,8750,25,200,300,2000,5000,30000,70000,450000)
pulse = c(1000,185,378,300,190,312,240,193,670,420,300,205,120,85,72,38)
MyAnimalData <- data.frame(cbind(type,animal,mass,pulse))
plot(pulse,mass)
plot(mass,pulse)
plot(pulse,mass)
install.packages(readr)
library(readr)
library(swirl)
swirl()
regrline<-lm(child~parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
fit<-lm(child ~ parent, galton)
fit$residuals
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
rhs-lhs
lhs-rhs
all.equal(lhs,rhs)
varChild<-var(galton$child)
varRes<-var(fit$residuals)
varEst<-est(ols.slope,ols.ic)
varEst<-est(ols.slope,ols.ic))
var(est(ols.slope, ols.ic))
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild, varRes, varEst)
all.equal(varChild,varEst+varRes)
efit <- lm(accel ~ mag+dist, attenu)
mean(efit$residuals)
cov(efit$residuals,attenu$mag)
cov(efit$residuals,attenu$dist)
sqrt(5)
sqrt(x=5)
sqrt(y=5)
x <- x+y
x <- 4
y<-x*x
# x<-9
x<-x+y
x
!( (1<2) | (2<1))
!( (1<2) | (2<1))
?exp
library(mtcars)
?mtcars
attach(mtcars)
names(mtcars)
colnames(mtcars)
mtcars [1,]
mtcars [,1]
mtcars [1,1]
mtcars[[1]]
getwd
getwd()
setwd(C:/Users/Senam Adedze/OneDrive - University of North Carolina at Chapel Hill/SP2024/LING460/data)
setwd(C:/Users/Senam Adedze/OneDrive - University of North Carolina at Chapel Hill/SP2024/LING460/data)
binom.test(x=18, n=60, p=1/2)
libray(lititanic)
libray(Titanic)
library(Titanic)
attach(Titanic)
install.packages(datasets)
install.packages("datasets")
install.packages("datasets")
library(titanic)
library(Titanic)
?Titanic
attach(Titanic)
class(Titanic)
as.data.frame(Titanic)
tfa23 <- subset(
as.data.frame(Titanic),
Sex=="Female" & Age=="Adult" & (Class=="2nd" | Class=="3rd"))
table(tfa23, Class=="2nd")
View(tfa23)
View(tfa23)
install.packages("magick")
library(magick)
getwd()
setwd("C:/Users/Senam Adedze/OneDrive - University of North Carolina at Chapel Hill/SP2024/GEOG456/geog456repo/hw8")
# Read the TIFF image
image <- image_read("an2004.tif")
# Write the image as a PNG file
image_write(image, "an2004.png")
# Write the image as a PNG file
image_write(image, "an2004.png")
image2 <- image_read("an2012.tif")
# Write the image as a PNG file
image_write(image, "an2012.png")
image3 <- image_read("an2018.tif")
# Write the image as a PNG file
image_write(image, "an2018.png")
